FROM python:3.10-slim as builder

WORKDIR /app

# Install Poetry and build dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends build-essential && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    pip install poetry

# Copy the project files
COPY . .

# Export dependencies to requirements.txt
RUN poetry export -f requirements.txt --output requirements.txt --without-hashes

# Second stage: Production image
FROM python:3.10-slim

WORKDIR /app

# Install runtime dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends libxml2 && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Copy requirements and install
COPY --from=builder /app/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt && \
    pip install --no-cache-dir flask gunicorn redis rq

# Copy application code
COPY . .

# Create necessary directories
RUN mkdir -p ./print3D_example ./output ./hygiene

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PORT=5000
# Use local Redis for testing if not provided
ENV REDIS_URL=redis://localhost:6379

# Expose the port
EXPOSE 5000

# Use a shell script to handle environment variable substitution properly
RUN echo '#!/bin/bash\n\n# Determine whether to run web or worker based on DYNO env var\nif [[ "$DYNO" == *"web"* ]]; then\n  echo "Starting web process..."\n  exec gunicorn --bind 0.0.0.0:$PORT --timeout 30 --threads=4 --workers=1 --keep-alive=5 --access-logfile=- app:app\nelse\n  echo "Starting worker process..."\n  exec rq worker --url $REDIS_URL graphrag_processing\nfi' > /app/docker-entrypoint.sh && \
    chmod +x /app/docker-entrypoint.sh

# Command to run - using exec form with entrypoint script
CMD ["/app/docker-entrypoint.sh"]